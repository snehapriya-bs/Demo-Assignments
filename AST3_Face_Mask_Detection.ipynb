{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "maritime-miami"
   },
   "source": [
    "## Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "95F1ym6qB8VU"
   },
   "source": [
    "At the end of the experiment, you will be able to :\n",
    "\n",
    "* load the image dataset using ImageDataGenerator from the path directory\n",
    "* perform data augmentation on the fly and create  batches of the dataset\n",
    "* build the convolutional neural networks for classification problem\n",
    "* visualize & interpret what CNN layers learn\n",
    "* use the transfer learning (pre-trained models) for classification problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "29152de7"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "This project uses a Deep Neural Network, more specifically a Convolutional Neural Network, to differentiate between images of people, with masks, without masks and incorrectly placed masks. Manually built and pretrained networks will be used to perform this classification task.\n",
    "\n",
    "**Face-Mask-Detection-Using-CNN**\n",
    "\n",
    "* Outbreak of the Coronavirus pandemic has created various changes in the lifestyle of everyone around the world.\n",
    "* Among these changes, wearing a mask has been very vital to every individual.\n",
    "* Detection of people who are not wearing masks is a challenge due to the large populations.\n",
    "* This face mask detection project can be used in schools, hospitals, banks, airports etc as a digitalized scanning tool.\n",
    "  - The technique of detecting peopleâ€™s faces and segregating them into three classes namely the people with masks and people without masks and partial masks is done with the help of image processing and deep learning.\n",
    "* With the help of this project, a person who is monitoring the face mask status for a particular firm can be seated in a remote area and still monitor efficiently and give instructions accordingly.\n",
    "\n",
    "![img](https://cdn.iisc.talentsprint.com/CDS/MiniProjects/dataset-images-with-mask.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kgx1PkHfCDyJ"
   },
   "source": [
    "## Dataset\n",
    "\n",
    "The data for this mini-project is collected from various sources including the masked images from internet and general frontal face images considered as without mask. This dataset consists of 5029 train images and 1059 test images with 3 classes `with_mask`, `without_mask` and `partial_mask`\n",
    "\n",
    "Many people are not correctly wearing their masks due to bad practices, bad behaviors or vulnerability of individuals (e.g., children, old people). For these reasons, several mask wearing campaigns intend to sensitize people about this problem and good practices. In this sense, this work proposes three types of masked face detection dataset\n",
    "  \n",
    "- Without Mask/ With Mask/ Partial Mask\n",
    "  \n",
    "Note that this dataset contains some annotated (artificially generated) masks to augment the 'masked' data category."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ih-oasWmdZul"
   },
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-18cjyCTCHE-"
   },
   "source": [
    "To build and implement a Convolutional Neural Network model to classify between masked/unmasked/partially masked faces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "operating-latter"
   },
   "source": [
    "## Grading = 10 Points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "abstract-stocks"
   },
   "source": [
    "### Import Required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YG52PDGENRgN"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Input, ZeroPadding2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense,Dropout\n",
    "from keras.models import Model, load_model\n",
    "from keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import glob, os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aYSjwlcSGJq1"
   },
   "source": [
    "### Analyzing the shape and distribution of datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rFRK7AO75NlR"
   },
   "source": [
    "Store the list of the paths from the training dataset for images of partial-mask, with_mask, and without_mask in variables partial, on, and off respectively. Hint : [Check the 'glob' section.](https://realpython.com/working-with-files-in-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z_FC0knCfeFD"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nJxCfK2p5gDd"
   },
   "source": [
    "Store paths of all three types of images in one variable. Check and store the height and width of each image.\n",
    "\n",
    "Hint: Use PIL(PIL.Image.open) library to open the image from the path, convert it into a NumPy array and check for shape.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jPbrQoQGGRh8"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-wwYXoG_Gok1"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hj9-n2Vw5u5E"
   },
   "source": [
    "Discuss the distribution of images. Calculate and display max, min and average of height and width of all images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jR21tLffHWPy"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QCKfnNWq4XFA"
   },
   "source": [
    "### Visualize the sample images of each class before augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wyywbhUZ31q1"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FnM7KwSC17C0"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5_icWF1CCLwY"
   },
   "source": [
    "### Load the images using ImageDataGenerator\n",
    "\n",
    "There are two main steps involved in creating the generator.\n",
    "1. Instantiate ImageDataGenerator with required arguments to create an object\n",
    "2. Use the `flow_from_directory` command depending on how your data is stored on disk. This is the command that will allow you to generate and get access to batches of data on the fly.\n",
    "\n",
    "Hint: [link](https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LqsC5w4f5NOr"
   },
   "outputs": [],
   "source": [
    "TRAINING_DIR = \"/content/MP2_FaceMask_Dataset/train/\"\n",
    "VALIDATION_DIR = \"/content/MP2_FaceMask_Dataset/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BBmLkk-zNeZs"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oUc5C57Fp4Zu"
   },
   "source": [
    "Check class indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5LZ3mguSHjD7"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5GgiFlxFqLG3"
   },
   "source": [
    "Check the shape of the image from train_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z3vJcC-4-YCi"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Es9FGxUjbyHM"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vdQY-dzZeqWm"
   },
   "source": [
    "### Visualize a few sample images using data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HCgAcqdGewsb"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-bnS1Mpkm671"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tY_0BwOICQXi"
   },
   "source": [
    "## Build the CNN model using Keras\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x1GGjQTfTIoO"
   },
   "source": [
    "**Convolutional Neural Network:** A neural network in which at least one layer is a convolutional layer. A typical convolutional neural network consists of some combination of the following layers:\n",
    "\n",
    "* convolutional layers\n",
    "* pooling layers\n",
    "* dense layers\n",
    "\n",
    "\n",
    "**Conv2D**  \n",
    "\n",
    "Passing an image with input shape of 3-D and to calculate the output:\n",
    "\n",
    " $O = \\frac{n - f + 2p}{s} + 1$\n",
    "\n",
    " where\n",
    "\n",
    " $n$ = image dimension\n",
    "\n",
    " $f$ = filter size\n",
    "\n",
    " $p$ = padding\n",
    "\n",
    " $s$ = stride\n",
    "\n",
    "**MaxPool**\n",
    "\n",
    "The resulting output, when using the \"valid\" padding option, has a spatial shape (number of rows or columns) of:\n",
    "\n",
    "O = `math.floor`$(\\frac{input shape - pool size)}{ strides}) + 1$ (when input shape >= pool size)\n",
    "\n",
    "The resulting output shape when using the \"same\" padding option is:\n",
    "\n",
    "O = `math.floor`$(\\frac{input shape - 1}{strides}) + 1$\n",
    "\n",
    "by default, stride = None, so stride is same as pool size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PmGNu31vmLhs"
   },
   "source": [
    "Task-flow\n",
    "* Initialize the network of convolution, maxpooling and dense layers\n",
    "* Define the optimizer and loss functions\n",
    "* Fit the model and evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2pqSFUUIca6f"
   },
   "source": [
    "**model 1 with 2 convolutional (feature representation) and 2 maxpool layers (down sampling) and 2 dense layers for classification.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TdaobFneNaJO"
   },
   "outputs": [],
   "source": [
    "model1 = Sequential([\n",
    "    # YOUR CODE HERE          #convolutional layer 1: No. of filters=100, filter size=3x3, activation = relu, input_shap = 224x224x3,\n",
    "    # YOUR CODE HERE                                                         #Maxpooling2D filter size=2x2\n",
    "\n",
    "   # YOUR CODE HERE                                  #convolutional layer 2: No. of filters=100, filter size=3x3, activation = relu,\n",
    "   # YOUR CODE HERE                                                         #Maxpooling2D filter size=2x2\n",
    "\n",
    "# YOUR CODE HERE\n",
    "])\n",
    "# Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u36QS6Tm8f5J"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "#Note: Applying a convolution to an image will make it smaller (if no padding).\n",
    "#Convolving a 3x3 filter over images means weâ€™ll lose a single pixel on all sides (2 in total).\n",
    "#In the given case, sliding a 3x3 filter over a 224x224 image results in a 222x222 image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_SvusGidrxAQ"
   },
   "source": [
    "Fit the data to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "483fUjrwUKbM"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5-27p6CRr80e"
   },
   "source": [
    "Plot training and validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pj8p_8pXx5xJ"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AJdl7ZnwUOlF"
   },
   "source": [
    "**model 2 with few more conv layers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NIAIxUljLoTV"
   },
   "source": [
    "Task-flow\n",
    "* Initialize the network of convolution, maxpooling and dense layers\n",
    "* Define the optimizer and loss functions\n",
    "* Define callback list\n",
    "* Fit the model and evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eVHFu7HDsILn"
   },
   "source": [
    "Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R-FrPZO1aFMM"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "erZI0giVsUeA"
   },
   "source": [
    "Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CcY4qtwln-dc"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tkyeIBMssnzm"
   },
   "source": [
    "Define Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o8BP42MFpXaS"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vThSsATZswHG"
   },
   "source": [
    "Fit the data to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VMOqcNE3Clfk"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "68k7j7Zvs3Ch"
   },
   "source": [
    "Plot training and validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bu9ceW13fuuc"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eu18F7bj_6vX"
   },
   "source": [
    "## Prediction on a random test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JgQVJJL6-4gc"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PEKRjtWw-owG"
   },
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nz52TNuhM1vr"
   },
   "source": [
    "Define a function 'get_img_array' that takes two parameters image path and target size. It returns the converted image to array.\n",
    "\n",
    "Display this image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RRkg6lqnAtgn"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n93GVtSaNU4h"
   },
   "source": [
    "## Instantiating a model that returns \"layer activations\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yOEsUuVVNj-n"
   },
   "source": [
    "Hint:: Use 'keras.model' to define this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PuiFdJBx_8To"
   },
   "outputs": [],
   "source": [
    "# Instantiating a model that returns \"layer activations\"\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "itxw1Gs8NuOE"
   },
   "source": [
    "Once the activation model is defined, predict the image tensor created using this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CSFiBeeQAhtD"
   },
   "outputs": [],
   "source": [
    "# Compute layer activations\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wfv4dDqIN8op"
   },
   "source": [
    "## Visualize first feature map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nASl1qTGD6j0"
   },
   "outputs": [],
   "source": [
    "# Visualise activation\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ECWxnbypELWO"
   },
   "source": [
    "## Visualize feature map after each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6e5iR4iCEIPV"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2b17iR7EElV_"
   },
   "source": [
    "Successive feature maps are of smaller dimensions but scaled to be the same size during visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AXYX3eqlExCX"
   },
   "source": [
    "## Visualise all the feature maps of all the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "13B37W3cE9bh"
   },
   "outputs": [],
   "source": [
    "# Post-processing code - only visualizaton\n",
    "# Visualizing every channel in every intermediate activation\n",
    "# YOUR CODE HERE\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mTBEIn05OkSQ"
   },
   "source": [
    "## Print the names of  conv and MaxPooling layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qjF8qqckOnsO"
   },
   "source": [
    "Hint:: 'model2.layer'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r5AlNWOwGavA"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oEg-69f4OwV0"
   },
   "source": [
    "## Create a feature extractor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5_I6xvO6GvIa"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "# Check the model summary\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kESdOQRoO6RH"
   },
   "source": [
    "## Use the feature extractor model to extract feature out of the image tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p8xP0MEnHJbQ"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9l15pw-NQSwp"
   },
   "source": [
    "Define a function 'compute_loss' it takes two arguments, image and filter index. It returns the filter activation using 'tf.reduce_mean'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "veUp4pMQHRzE"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fdNI5i63RBya"
   },
   "source": [
    "## Loss maximization via stochastic gradient ascent.\n",
    "Define a function to implement this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ikONyhrWHVr-"
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y1Ha0GAORPOP"
   },
   "source": [
    "## Define a function to generate filter visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zcm6kLJZzaTu"
   },
   "source": [
    "This function uses gradient ascent to generate an image that maximizes the activation of a given filter in a CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3jBdkBWFHZon"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r_MJfH52RVrK"
   },
   "source": [
    "## Define a function to convert a tensor into a valid image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4dTx6TA0HdC4"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TED6w8Zi_O01"
   },
   "source": [
    "Generate a list of images, where each image in the list represents the activation pattern of a particular filter in the given layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kErKQYxsJffX"
   },
   "outputs": [],
   "source": [
    "# Post processing- Just visualization\n",
    "# Generating a grid of all filter response patterns in a layer\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MoguWV0G_kHl"
   },
   "source": [
    "Stitch together all the images in the 'all_images' list and save the resulting image as a PNG file. The resulting image shows a grid of all the filter activation patterns in the given layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yEnlc8iNHzYy"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kvlt9ZqA_zvu"
   },
   "source": [
    "Display the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "829Vp33tJyRY"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "djPt76WMRnc3"
   },
   "source": [
    "All the steps discussed in visualization section can be easily understood from AST3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wFPKELTRnv9s"
   },
   "source": [
    "## Transfer Learning\n",
    "\n",
    "Transfer learning consists of taking features learned on one problem, and leveraging them on a new, similar problem.\n",
    "\n",
    "A pre-trained model is a saved network that was previously trained on a large dataset, typically on a large-scale image-classification task.\n",
    "\n",
    "The intuition behind transfer learning for image classification is that if a model is trained on a large and general enough dataset, this model will effectively serve as a generic model of the visual world. You can then take advantage of these learned feature maps without having to start from scratch by training a large model on a large dataset.\n",
    "\n",
    "For eg. Using VGG16, we remove the last layer which takes a probability for each of the 1000 classes in the ImageNet and replaces it with a layer that takes 3 probabilities in our case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wWXBTiIGCox1"
   },
   "source": [
    "### Use the pre-trained models ([VGG16](https://www.tensorflow.org/api_docs/python/tf/keras/applications/vgg16/VGG16) or [ResNet50](https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet50/ResNet50))\n",
    "\n",
    "* Load the pre-trained model\n",
    "* Fit and evaluate the data\n",
    "\n",
    "Hint: [How to use pre-trained model](https://drive.google.com/file/d/1d5WSWQmdVYYcJhvhMcZMoK5-BPOC1B_7/view?usp=sharing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7YI0gnq-DLyu"
   },
   "source": [
    "#### Expected accuracy: More than 90%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y4GX9CwFqOXm"
   },
   "source": [
    "Task-flow\n",
    "* Initialize the network with the weights of Imagenet\n",
    "* Fine tune the network by modifying fully connected layers.\n",
    "* Re-train the model with our problem data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V5IsJY7ZVuQM"
   },
   "source": [
    "#### VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hvdX6Whx__xN"
   },
   "source": [
    "Define the pre-trained vgg model with dense layers.\n",
    "\n",
    "Display the model summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9r8Te6R9c27S"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8w9JPHLrlS9w"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "40etmYzwAUgZ"
   },
   "source": [
    "Fit the data to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ICVNeRSeNotA"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YUup-3FZAcCc"
   },
   "source": [
    "Plot training and validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qhl2k4Ekf4he"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qr5HVPfiV26t"
   },
   "source": [
    "#### ResNet50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5KqOeFkxAkaa"
   },
   "source": [
    "Define the pre-trained resnet model with dense layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nx2Z2vLZqXm0"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uFPzqM63AzmK"
   },
   "source": [
    "Fit the data to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MX9UWVFJPldz"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2DdiGI3A8Ag"
   },
   "source": [
    "Plot the validation and training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i2miNoWCgAXs"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4tF71VIUwzK"
   },
   "source": [
    "### Capture the live image using the below code cell and predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "I6kTLnTmrcCg"
   },
   "outputs": [],
   "source": [
    "#@title Capture the photo\n",
    "from IPython.display import display, Javascript\n",
    "from google.colab.output import eval_js\n",
    "from base64 import b64decode\n",
    "\n",
    "def take_photo(filename='photo.jpg', quality=0.8):\n",
    "  js = Javascript('''\n",
    "    async function takePhoto(quality) {\n",
    "      const div = document.createElement('div');\n",
    "      const capture = document.createElement('button');\n",
    "      capture.textContent = 'Capture';\n",
    "      div.appendChild(capture);\n",
    "\n",
    "      const video = document.createElement('video');\n",
    "      video.style.display = 'block';\n",
    "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
    "\n",
    "      document.body.appendChild(div);\n",
    "      div.appendChild(video);\n",
    "      video.srcObject = stream;\n",
    "      await video.play();\n",
    "\n",
    "      // Resize the output to fit the video element.\n",
    "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
    "\n",
    "      // Wait for Capture to be clicked.\n",
    "      await new Promise((resolve) => capture.onclick = resolve);\n",
    "\n",
    "      const canvas = document.createElement('canvas');\n",
    "      canvas.width = video.videoWidth;\n",
    "      canvas.height = video.videoHeight;\n",
    "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
    "      stream.getVideoTracks()[0].stop();\n",
    "      div.remove();\n",
    "      return canvas.toDataURL('image/jpeg', quality);\n",
    "    }\n",
    "    ''')\n",
    "  display(js)\n",
    "  data = eval_js('takePhoto({})'.format(quality))\n",
    "  binary = b64decode(data.split(',')[1])\n",
    "  with open(filename, 'wb') as f:\n",
    "    f.write(binary)\n",
    "  return filename\n",
    "\n",
    "from IPython.display import Image\n",
    "try:\n",
    "  filename = take_photo()\n",
    "  print('Saved to {}'.format(filename))\n",
    "  display(Image(filename))\n",
    "except Exception as err:\n",
    "  print(str(err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rNe9vDQ6q6Z6"
   },
   "source": [
    "After executing above cell and capturing the photo, load the captured photo and predict with model.\n",
    "\n",
    "**Note:**\n",
    "* Convert the image to numpy array and resize to the shape which model accept.\n",
    "* Extend the dimension (to 4-D shape) of an image, as the model is trained on a batch of inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XD5gr9YOAX83"
   },
   "outputs": [],
   "source": [
    "# Make a prediction using model that is created by making use of transer learning technique\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fBIA1sbLByIL"
   },
   "source": [
    "### Report Analysis\n",
    "\n",
    "- Compare the accuracies for the Pre-trained vs CNN models\n",
    "- Which model detects the mask/no mask/ partial mask more accurately with the live pictures?\n",
    "- What process was followed to tune the hyperparameters?"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
