{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sNCzT95pcrIN"
   },
   "source": [
    "## Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IMBrLtAtcrIO"
   },
   "source": [
    "At the end of the mini-project, you will be able to :\n",
    "\n",
    "* perform data preprocessing, EDA on the resume dataset\n",
    "* fine-tune Bert model for resume classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v6Xda9CM9el9"
   },
   "source": [
    "## Dataset Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VeRfk4Sb9h0r"
   },
   "source": [
    "The data is in CSV format, with two features: Category, and Resume.\n",
    "\n",
    "**Category** -  Industry sector to which the resume belongs to, and\n",
    "\n",
    "**Resume** - The complete CV (text) of the candidate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Pped-3NPaDV"
   },
   "source": [
    "## Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QuxYf07d62Oo"
   },
   "source": [
    "Companies often receive thousands of resumes for each job posting and employ dedicated screening officers to screen qualified candidates. Finding suitable candidates for an open role from a database of 1000s of resumes can be a tough task. Automated resume categorization can speeden the candidate selection process. Such automation can really ease the tedious process of fair screening and shortlisting the right candidates and aid quick decisionmaking.\n",
    "\n",
    "To learn more about this, click [here](https://www.sciencedirect.com/science/article/pii/S187705092030750X)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uvvyWAPhkvm8"
   },
   "source": [
    "**Problem Statement:** Fine-tune a pre-trained Bert model for resume classification.\n",
    "\n",
    "*For fine-tuning Bert, refer to the HuggingFace platform session held on 17 Aug.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lNKEGvMEIK5f"
   },
   "source": [
    "### Install dependencies\n",
    "\n",
    "After installing the below dependencies ***Restart the session/runtime***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ejNC4T4_A0GN"
   },
   "outputs": [],
   "source": [
    "!pip -q uninstall pyarrow -y\n",
    "!pip -q install pyarrow==15.0.2\n",
    "!pip -q install datasets\n",
    "!pip -q install accelerate\n",
    "!pip -q install transformers\n",
    "\n",
    "# Ignore the Error/Warning showing after running this cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sTBUGx6zfgsJ"
   },
   "source": [
    "### <font color=\"#990000\">Restart Session/Runtime</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HdoX5Go6IhCE"
   },
   "source": [
    "### Import required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5t0FQjPs8o4s"
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer\n",
    "from transformers import pipeline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "standing-zimbabwe"
   },
   "source": [
    "### Downloading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T3FkLI6wcaat"
   },
   "source": [
    "**Exercise 1: Read the UpdatedResumeDataset.csv dataset [0.5 Mark]**\n",
    "\n",
    "**Hint:** pd.read_csv( , encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eIu-AOsB9GfD"
   },
   "outputs": [],
   "source": [
    "# Read the dataset\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QvddL7X69NiB"
   },
   "source": [
    "### Pre-processing and EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EA1d25HrzTGW"
   },
   "source": [
    "**Exercise 2: Display  all the categories of resumes and their counts in the dataset **\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C92ji6ZV9MWs"
   },
   "outputs": [],
   "source": [
    "# Display the distinct categories of resume\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hcvr3-nQn1PN"
   },
   "outputs": [],
   "source": [
    "# Displaying the number of distinct categories of resume\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YtIjY7ji9va5"
   },
   "outputs": [],
   "source": [
    "# Display the distinct categories of resume and the number of records belonging to each category\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kpHv50ojzvO5"
   },
   "source": [
    "**Exercise 3: Create the count plot of different categories **\n",
    "\n",
    "**Hint:** Use `sns.countplot()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zYwrK_5f93gP"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VyXtz0Mr0NVB"
   },
   "source": [
    "**Exercise 4: Create a pie plot depicting the percentage of resume distributions category-wise.**\n",
    "\n",
    "**Hint:** Use [plt.pie()](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.pie.html) and [plt.get_cmap](https://matplotlib.org/stable/tutorials/colors/colormaps.html) for color mapping the pie chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qrpJDoGx-CuF"
   },
   "outputs": [],
   "source": [
    "targetCounts = df['Category'].value_counts()\n",
    "targetLabels  = targetCounts.index\n",
    "# Make square figures and axes\n",
    "plt.figure(1, figsize=(25,25))\n",
    "the_grid = GridSpec(2, 2)\n",
    "\n",
    "# YOUR CODE HERE to display pie chart with color coding (eg. `coolwarm`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KJaznteJ1xr4"
   },
   "source": [
    "**Exercise 5: Convert all the `Resume` text to lower case and remove trailing spaces **\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tf1wNRqb-Om2"
   },
   "outputs": [],
   "source": [
    "# Convert all characters to lowercase and remove trailing spaces\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8cBXmdXpDIQJ"
   },
   "source": [
    "### Cleaning Resume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yvkRbRnM3ap7"
   },
   "source": [
    "**Exercise 6: Define a function to clean the resume text**\n",
    "\n",
    "In the text there are special characters, urls, hashtags, mentions, etc. You need to remove for the following:  \n",
    "\n",
    "* URLs: For reference click [here](https://stackoverflow.com/questions/11331982/how-to-remove-any-url-within-a-string-in-python)\n",
    "* RT | cc: For reference click [here](https://www.machinelearningplus.com/python/python-regex-tutorial-examples/)\n",
    "* Hashtags, # and Mentions, @\n",
    "* punctuations\n",
    "* extra whitespace\n",
    "\n",
    "PS: Use the provided reference similarly for removing any other such elements.\n",
    "\n",
    "After cleaning as above, store the Resume Text in a separate column (New Feature say `Cleaned_Resume`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k9Z-Oois_LWE"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def cleanResume(resumeText):\n",
    "    # YOUR CODE HERE\n",
    "    #\n",
    "    #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0O2tR_IjDNWr"
   },
   "outputs": [],
   "source": [
    "# Apply the function defined above and save the\n",
    "df['Cleaned_Resume'] =  # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2pBLoWMxAf64"
   },
   "source": [
    "**Exercise 7: Convert the categorical variable `Category` to a numerical feature and make a different column <font color=\"#990000\">`label`</font>, which can be treated as the target variable [0.5 Mark]**\n",
    "\n",
    "**Hint:** Use [`sklearn.preprocessing.LabelEncoder()`](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html) method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kg4QNr7DYSJ5"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "df[\"label\"] = # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UWKiazN5mdyQ"
   },
   "source": [
    "**Exercise 8: Plot the histogram of words count of `Cleaned_Resume` text **\n",
    "\n",
    "**Hint:** Use sns.distplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mieV5cpRlUAq"
   },
   "outputs": [],
   "source": [
    "df['Count'] = # YOUR CODE HERE to count number of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4tK8VZkyldQx"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize= (8, 8))\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zK2N4kjkSEjF"
   },
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y6MTKhUomkzU"
   },
   "source": [
    "**Exercise 9: Split the dataset into training, validation, and testing set **\n",
    "\n",
    "* Do stratified splitting using `label` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mP2Ay3GdFU7b"
   },
   "outputs": [],
   "source": [
    "train_test_df, val_df = # YOUR CODE HERE to split data\n",
    "train_df, test_df = # YOUR CODE HERE to split data\n",
    "\n",
    "len(train_df), len(val_df), len(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IHuVoyE6F6ef"
   },
   "outputs": [],
   "source": [
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vQNG09lz2VG6"
   },
   "source": [
    "### Convert to HuggingFace Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qEpf_GllUIbt"
   },
   "source": [
    "**Exercise 10: Convert Pandas dataframe to HuggingFace Dataset **\n",
    "\n",
    "**Hint:**\n",
    "\n",
    "    import pandas as pd\n",
    "    from datasets import Dataset, DatasetDict\n",
    "\n",
    "    tdf = pd.DataFrame({\"a\": [1, 2, 3], \"b\": ['hello', 'ola', 'thammi']})\n",
    "    vdf = pd.DataFrame({\"a\": [4, 5, 6], \"b\": ['four', 'five', 'six']})\n",
    "    tds = Dataset.from_pandas(tdf)\n",
    "    vds = Dataset.from_pandas(vdf)\n",
    "\n",
    "    ds = DatasetDict()\n",
    "\n",
    "    ds['train'] = tds\n",
    "    ds['validation'] = vds\n",
    "\n",
    "    print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z_89zi9XF5J0"
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "train_ds = # YOUR CODE HERE\n",
    "val_ds = # YOUR CODE HERE\n",
    "test_ds = # YOUR CODE HERE\n",
    "\n",
    "ds = DatasetDict()\n",
    "\n",
    "ds['train'] = train_ds\n",
    "ds['validation'] = val_ds\n",
    "ds['test'] = test_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IXsHhNqcVyUb"
   },
   "source": [
    "### Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EqmNgMaQVNdp"
   },
   "source": [
    "**Exercise 11: Load tokenizer for checkpoint `distilbert-base-uncased` **\n",
    "\n",
    "**Hint:** `AutoTokenizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iKAaBbGhq3cP"
   },
   "outputs": [],
   "source": [
    "# Load tokenizer\n",
    "tokenizer = # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "89dlcyQkIL-Q"
   },
   "outputs": [],
   "source": [
    "def tokenize_fn(batch):\n",
    "    # YOUR CODE HERE..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z_c7_2tYI7Nt"
   },
   "outputs": [],
   "source": [
    "tokenized_datasets = ds.map(tokenize_fn, batched=True)\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TPXfBiYpElKx"
   },
   "source": [
    "### Load Pre-Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z_14j98LV2Tg"
   },
   "source": [
    "**Exercise 12: Load pre-trained Bert model with checkpoint `distilbert-base-uncased` and show model summary **\n",
    "\n",
    "**Hint:** `AutoModelForSequenceClassification`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tHeD1YZu-iA9"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OEaFCpYAFLzC"
   },
   "source": [
    "**Exercise 13: Freeze/Un-Freeze different layers  [0.5 Mark]**\n",
    "\n",
    "**Hint:** Freeze layers starting with name *distilbert*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XrMTbGJaf0fz"
   },
   "outputs": [],
   "source": [
    "# Display layers name\n",
    "\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vl9qw4l2IPIA"
   },
   "outputs": [],
   "source": [
    "# Freezing\n",
    "\n",
    "# YOUR CODE HERE.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "id": "-rpzN_c6HRTR"
   },
   "outputs": [],
   "source": [
    "# Display layers gradient\n",
    "\n",
    "# YOUR CODE HERE.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_1fnp2FMLAbA"
   },
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HD4C2Z8bNuQf"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0a_pwKLaPO5h"
   },
   "outputs": [],
   "source": [
    "f1_score(y_true=[1,0,1], y_pred=[1,0,0], average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DWtXcsbnQcc-"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(logits_and_labels):\n",
    "    logits, labels = logits_and_labels\n",
    "    predictions = np.argmax(logits,axis=-1)\n",
    "    return {'f1_score': f1_score(y_true=labels, y_pred=predictions, average='weighted')}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lRCoqRSWLSu9"
   },
   "source": [
    "**Exercise 14: Fine-tune model on train dataset  [0.5 Mark]**\n",
    " * Create `TrainingArguments` class object\n",
    " * Create `Trainer` class  object\n",
    " * Train it for higher number of epochs say 40 or 50\n",
    " * Switch to GPU runtime if needed\n",
    "\n",
    "**Hint:** Check if the training code is running without any error with CPU runtime, later switch to GPU runtime for faster training. Once trained, save the model, create its zip file, and download into your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p9mRRxP41j13"
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "from transformers import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DVZwc4qv2kYz"
   },
   "outputs": [],
   "source": [
    "# Set up the training arguments\n",
    "\n",
    "model_output_path = \"/content/bert_model\"\n",
    "\n",
    "training_args = # YOUR CODE HERE.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NCkulT251mCW"
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "trainer = # YOUR CODE HERE.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZcgsEYJlKbR0"
   },
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r0-EFIfIGAwB"
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "trainer.save_model('saved_bert_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h3SgH3qXGA1S"
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e7KOsH5j6fkP"
   },
   "outputs": [],
   "source": [
    "# Create a Zip file and download\n",
    "!zip -r saved_bert_model.zip saved_bert_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6GxwVdGLKgPe"
   },
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kkX_uGuNaePi"
   },
   "source": [
    "**Exercise 15: Load the saved model and create a pipeline to perform text classification **\n",
    "\n",
    " * Create the pipeline object for text classification\n",
    " * Create a `make_prediction` function to use pipeline object and output the prediction label\n",
    "\n",
    "**Hint:** pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zh3Dvzz-GBEr"
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SKjG3Gm0Gb1Z"
   },
   "outputs": [],
   "source": [
    "my_model = # YOUR CODE HERE.. to load text classification pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AvSyk5jylTz7"
   },
   "outputs": [],
   "source": [
    "# Function to predict label for a resume text\n",
    "\n",
    "def make_prediction(input_text):\n",
    "\n",
    "    # YOUR CODE HERE..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BARs_uj-lTxH"
   },
   "outputs": [],
   "source": [
    "# Test prediction\n",
    "make_prediction('programming, web designing, coding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jUPAf9tR8yEC"
   },
   "outputs": [],
   "source": [
    "make_prediction('continuous integration and continuous delivery')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vRgaCbxzExGC"
   },
   "outputs": [],
   "source": [
    "make_prediction('law student and journalist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SG_mZItOqG2v"
   },
   "outputs": [],
   "source": [
    "make_prediction('machine learning, data, EDA, big data, neural networks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mr0xI6QwFN-Q"
   },
   "source": [
    "## **Optional**: Create a Gradio based web interface to test and display the model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wl0ngdnKjKHH"
   },
   "outputs": [],
   "source": [
    "!pip -q install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3XwCJSdDDVVU"
   },
   "outputs": [],
   "source": [
    "import gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bpRnUY5w551-"
   },
   "outputs": [],
   "source": [
    "# Textbox to take Input from user\n",
    "in_text = gradio.Textbox(lines=10, placeholder=None, value=\"Enter resume text here\", label='Resume Text')\n",
    "\n",
    "\n",
    "# Textbox to display Output prediction\n",
    "out_label = gradio.Textbox(type=\"text\", label='Predicted Class Label')\n",
    "\n",
    "\n",
    "# Gradio interface to create UI\n",
    "iface = gradio.Interface(fn = make_prediction,             # fine-tuned model is used inside this function\n",
    "                         inputs = [in_text],\n",
    "                         outputs = [out_label],\n",
    "                         title = \"Resume Classification\",\n",
    "                         description = \"Using fine-tuned Bert model\",\n",
    "                         allow_flagging = 'never')\n",
    "\n",
    "\n",
    "# Launch interface\n",
    "iface.launch(share = True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
