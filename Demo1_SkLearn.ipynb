{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "93OhtrPFI3Cv"
   },
   "source": [
    "## Learning Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VCt0SUxASryl"
   },
   "source": [
    "At the end of the experiment, you will be able to:\n",
    "\n",
    "- appreciate the significance of a pipeline and hyper-parameter tuning\n",
    "- setup a machine learning pipeline\n",
    "- perform hyper-parameter tuning\n",
    "- know techniques to analyze the results of hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X5uhFSfxJppc"
   },
   "source": [
    "## Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fhtMbxlbSZOc"
   },
   "source": [
    "**ML Pipeline**\n",
    "\n",
    "A machine learning pipeline can be created by putting together a sequence of steps involved in training a machine learning model. It can be used to automate a machine learning workflow. The pipeline can involve pre-processing, feature selection, classification/regression, and post-processing steps. More complex applications may need to fit in other necessary steps within this pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6eC1QBzs1OZO"
   },
   "source": [
    "**Problem Statement**\n",
    "\n",
    "Substances in traditional fire-extinguishing techniques may leave chemical waste, harm human health and cause social and economic damages. Therefore research on fire-extinguishing using renewable energy sources is important. The impact of sound waves on flame and combustion behavior of fuel is a common.\n",
    "\n",
    "Fire is a chemical reaction that breaks out with the combination of heat, fuel, and oxygen components. The heat, gas, and smoke resulting from this oxidation reaction may significantly harm to human and the environment. Early intervention to the fire facilitates to extinguish. However, **depending on the scale of the fire and the fuel type, fire-extinguishing agents may vary**. These substances in traditional fire-extinguishing techniques may leave chemical waste and harm human health. Additionally, it can also cause social and economic damages. In order to eliminate these impacts, researches on fire-extinguishing with renewable energy sources have been carried out. Currently, **the impact of sound waves on flame and combustion behavior of fuel is a common research topic**. The pressure changes in the air as a result of the sound waves lead to the occurrence of airflow. This airflow changes the behavior of the flame, fuel, and oxygen in the environment. The airflow created by the sound waves enables the fuel to spread over a wider surface. At this phase, the flame shows the tendency of spreading over a wide area together with the fuel. Fuel consumption also increases by the fuel particle oscillation due to the spread of flame and sound waves. While these stages are taking place, the air in the fire environment mixes and the amount of oxygen decreases as a result of the compression and expansion movements in the air. Through the combination of these three events, the flame can be extinguished. Necessary frequency ranges are available for the flame to be extinguished with the sound waves. Besides the frequency characteristic of sound waves, sound intensity level and the distance are also the factors having an impact on the ability to extinguish the flame.\n",
    "\n",
    "Utilizing the fire characteristics, studies have been carried out to estimate the parameters necessary for the detection and extinguishing of the fire. The **data have been obtained by examining the characteristics of the flames extinguished using sound waves**. Statistical analysis and classification algorithms using these data provide information on the behaviour of the flame.\n",
    "\n",
    "\n",
    "To know more about the experiment, click [here](https://ieeexplore.ieee.org/document/9452168)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hk4BqqzecR1K"
   },
   "source": [
    "## Dataset Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NuMzOs9LJ6zk"
   },
   "source": [
    "The **Acoustic Extinguisher Fire Dataset** was obtained as a result of the extinguishing tests of four different fuel flames with a sound wave extinguishing system. The sound wave fire-extinguishing system consists of 4 subwoofers with a total power of 4,000 Watt placed in the collimator cabinet. There are two amplifiers that enable the sound come to these subwoofers as boosted. Power supply that powers the system and filter circuit ensuring that the sound frequencies are properly transmitted to the system is located within the control unit. While computer is used as frequency source, anemometer was used to measure the airflow resulted from sound waves during the extinguishing phase of the flame, and a decibel meter to measure the sound intensity. An infrared thermometer was used to measure the temperature of the flame and the fuel can, and a camera is installed to detect the extinction time of the flame. A total of 17,442 tests were conducted with this experimental setup.\n",
    "\n",
    "The experiments are planned as follows:\n",
    "\n",
    "- Three different liquid fuels and LPG fuel were used to create the flame.\n",
    "- 5 different sizes of liquid fuel cans are used to achieve different size of flames.\n",
    "- Half and full gas adjustment is used for LPG fuel.\n",
    "- While carrying out each experiment, the fuel container, at 10 cm distance, was moved forward up to 190 cm by increasing the distance by 10 cm each time.\n",
    "- Along with the fuel container, anemometer and decibel meter were moved forward in the same dimensions.\n",
    "- Fire extinguishing experiments was conducted with 54 different frequency sound waves at each distance and flame size.\n",
    "Throughout the flame extinguishing experiments, the data obtained from each measurement device was recorded and a dataset was created.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aO4pFGacmA0S"
   },
   "source": [
    "The dataset includes following features:\n",
    "\n",
    "- **SIZE:** *fuel container size representing the flame size* [7cm=1, 12cm=2, 14cm=3, 16cm=4, 20cm=5, Half throttle setting=6, Full throttle=7]\n",
    "- **FUEL:** *fuel type* [gasoline, thinner, kerosene, lpg]\n",
    "- **FREQUENCY:** *sound frequency* [1 - 75 Hz]\n",
    "- **DECIBEL:** *sound intensity* [72 - 113 dB]\n",
    "- **DISTANCE:** *bw fuel container and fire-extinguishing system* [10 - 190 cm]\n",
    "- **AIRFLOW:** *airflow resulted from sound waves* [0 - 17 m/s]\n",
    "- **STATUS:** *flame extinction* [0 indicates the non-extinction state, 1 indicates the extinction state] ***(dependent/target variable)***\n",
    "\n",
    "Accordingly, 6 input features and 1 output feature will be used in models.\n",
    "The status property (flame extinction or non-extinction states) can be predicted by using six features in the dataset. Status and fuel features are categorical, while other features are numerical. 8,759 of the 17,442 test results are the non-extinguishing state of the flame. 8,683 of them are the extinction state of the flame. According to these numbers, it can be said that the class distribution of the dataset is almost equal.\n",
    "\n",
    "To know more about the dataset, click [here](https://www.kaggle.com/datasets/muratkokludataset/acoustic-extinguisher-fire-dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BNLA8HiKxQhc"
   },
   "source": [
    "### Setup Steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "69RDKc0Rq6Le"
   },
   "source": [
    "### Import Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 803,
     "status": "ok",
     "timestamp": 1728217357586,
     "user": {
      "displayName": "Yograj Mahawar",
      "userId": "10906189549763051896"
     },
     "user_tz": -330
    },
    "id": "88_C4BgAFCH2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt                                 # For plotting data\n",
    "import seaborn as sns                                           # For plotting data\n",
    "from sklearn.model_selection import train_test_split            # For train/test splits\n",
    "from sklearn.tree import DecisionTreeClassifier                 # Classifier model\n",
    "from sklearn.feature_selection import VarianceThreshold         # Feature selector\n",
    "from sklearn.pipeline import Pipeline                           # For setting up pipeline\n",
    "\n",
    "# Various pre-processing steps\n",
    "from sklearn.preprocessing import Normalizer, StandardScaler, MinMaxScaler, PowerTransformer, MaxAbsScaler, LabelEncoder, OrdinalEncoder\n",
    "from sklearn.model_selection import GridSearchCV                # For Hyper-parameter tuning\n",
    "\n",
    "# To supress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "49YbZU_erJn4"
   },
   "source": [
    "### Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "69at-tNsTDcC"
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('Demo1_Acoustic_Extinguisher_Fire_Dataset.xlsx', sheet_name='A_E_Fire_Dataset')\n",
    "\n",
    "# Shape of dataframe\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H53GhbkwrQMw"
   },
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oefdmDE_UiCc"
   },
   "outputs": [],
   "source": [
    "# Show first few rows of dataframe\n",
    "df.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PVIuNmCPsDNn"
   },
   "source": [
    "From above it can be seen that:\n",
    "\n",
    "- There are 6 independent variables\n",
    "- `FUEL` is a categorical feature\n",
    "- Every other feature is numerical\n",
    "- `STATUS` is the dependent variable\n",
    "- It is a binary classification problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ot-_opHsraf"
   },
   "source": [
    "### Segregating the dataframe into independent and dependent features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4xcV5GOXcDT7"
   },
   "outputs": [],
   "source": [
    "# The data matrix X\n",
    "X = df.iloc[:, :-1]\n",
    "\n",
    "# The labels\n",
    "y = (df.iloc[:,-1:])\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GHGQcdQAdth6"
   },
   "outputs": [],
   "source": [
    "# Independent features\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EfJUVP_vEXiY"
   },
   "outputs": [],
   "source": [
    "# Independent features\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7mTbd38iEbA4"
   },
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ifhK8xQhtC2N"
   },
   "source": [
    "### Exploring the unique categories in categorical feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K4r1aHQtfibA"
   },
   "outputs": [],
   "source": [
    "# Unique values in FUEL column\n",
    "X['FUEL'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9tPMhs0YvnAP"
   },
   "outputs": [],
   "source": [
    "# Plot unique values in FUEL column\n",
    "uniques = X['FUEL'].value_counts()\n",
    "sns.barplot(x = uniques.index,\n",
    "            y = uniques.values,\n",
    "            hue=uniques.index            # color\n",
    "            )\n",
    "plt.xlabel(\"FUEL type\")\n",
    "plt.ylabel(\"Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CMhEIvL-kCSA"
   },
   "source": [
    "### Encoding the Categorical Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nLEf_IV8kAEW"
   },
   "outputs": [],
   "source": [
    "# Label encode input variable\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "X['FUEL'] = le.fit_transform(X[['FUEL']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ya-41ajjFtdL"
   },
   "outputs": [],
   "source": [
    "# Unique categories in 'FUEL' column\n",
    "le.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VDEmTnxG0Dvh"
   },
   "outputs": [],
   "source": [
    "X.tail(110)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "REdtfeKftWr1"
   },
   "source": [
    "After encoding, all the features are numerical in nature now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4cUIcML23n-L"
   },
   "outputs": [],
   "source": [
    "# Prediction features\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7qdzBidudvYk"
   },
   "outputs": [],
   "source": [
    "# Target feature: Extinction Status\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sxH87eA-tgZT"
   },
   "source": [
    "### Split the data into train and test sets\n",
    "\n",
    "To know more about `train_text_split()`, refer [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4y-f5vXOdxtN"
   },
   "outputs": [],
   "source": [
    "# Split the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,                  # predictors\n",
    "                                                    y,                  # labels\n",
    "                                                    test_size=1/3,      # test set size\n",
    "                                                    random_state=0,     # set random number generator seed for reproducibility\n",
    "                                                    stratify = y        # Use 'stratify' to ensure each set contains approximately the same percentage of samples of\n",
    "                                                                        # each target class as the complete set\n",
    "                                                    )\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "geoaygxSGsVn"
   },
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OUSm6pk-Gv4t"
   },
   "outputs": [],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "81xxistBUov5"
   },
   "source": [
    "### A Classifier Without a Pipeline and Hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MxxfOS4W_gJZ"
   },
   "source": [
    "First, let's just check how the DecisionTree performs on the training and test sets. This would give us a baseline for performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ZCOh1nn1ocA"
   },
   "outputs": [],
   "source": [
    "# Instantiate DecisionTree classifier and fit on train set\n",
    "dt_model = DecisionTreeClassifier(max_depth = 4,              # The maximum depth of the tree\n",
    "                                  max_features = 3,             # The number of features to consider when looking for the best split\n",
    "                                  min_samples_leaf = 4              # The minimum number of samples required to be at a leaf node\n",
    "                                  )\n",
    "\n",
    "dt_model.fit(X_train, y_train)\n",
    "\n",
    "# Performance on train and test sets\n",
    "print('Training set score: ' + str(dt_model.score(X_train,y_train)))\n",
    "print('Test set score: ' + str(dt_model.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iJ0JCvWsU7-e"
   },
   "source": [
    "### Setting Up a Machine Learning Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LLeFDVre_SZS"
   },
   "source": [
    "- **Scaler:** For pre-processing data, i.e., transform the data to zero mean and unit variance using the `StandardScaler()`.\n",
    "    - Scaling the features is not necessary for Tree based models like decision tree, xgboost, etc.\n",
    "\n",
    " To know more about StandardScaler, refer [here](https://scikit-learn.org/dev/modules/generated/sklearn.preprocessing.StandardScaler.html).\n",
    "\n",
    "- **Feature selector:** Use `VarianceThreshold()` for discarding features whose variance is less than a certain defined threshold.\n",
    "\n",
    "  To know more about VarianceThreshold, refer [here](https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.VarianceThreshold.html).\n",
    "\n",
    "- **Classifier:** `DecisionTreeClassifier()`, which implements a decision tree classifier.\n",
    "\n",
    " To know more about DecisionTreeClassifier, refer [here](https://scikit-learn.org/dev/modules/generated/sklearn.tree.DecisionTreeClassifier.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hoXhOD7HUv8m"
   },
   "outputs": [],
   "source": [
    "# Setup pipeline\n",
    "pipe = Pipeline([# ('scaler', StandardScaler()),               # Feature scaling is not necessary for Tree based models like decision tree\n",
    "                 ('selector', VarianceThreshold(threshold=0)),\n",
    "                 ('classifier', DecisionTreeClassifier(max_depth = 4, max_features = 3, min_samples_leaf = 4))\n",
    "                 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OuFKGI5l3wVW"
   },
   "outputs": [],
   "source": [
    "# Fit pipeline on train set\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Performance on train and test sets\n",
    "print('Training set score: ' + str(pipe.score(X_train,y_train)))\n",
    "print('Test set score: ' + str(pipe.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fowNWKfFVTx_"
   },
   "source": [
    "## Hyper-parameter Tuning with GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lbfwBrMPmdIT"
   },
   "source": [
    "<img src='https://drive.google.com/uc?id=1gFwuNHUAAgO7IoNq3m-wMXn3ABjpRKEj' width=800px>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LLDvhYpwnNFw"
   },
   "source": [
    "In the code below, weâ€™ll show the following:\n",
    "\n",
    "- We can search for the best scalers. Instead of just the `StandardScaler()`, we can try `MinMaxScaler()`, `Normalizer()`, and `MaxAbsScaler()`.\n",
    "\n",
    "- We can search for the best variance threshold to use in the selector, i.e., `VarianceThreshold()`.\n",
    "\n",
    "- We can search for the best value of max_depth for the `DecisionTreeClassifier()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xxy56w0E4kii"
   },
   "outputs": [],
   "source": [
    "parameters = {# 'scaler': [StandardScaler(), MinMaxScaler(), Normalizer(), MaxAbsScaler()],               # This line is commented since scaling is not included in pipeline\n",
    "              'selector__threshold': [0, 0.001, 0.01],\n",
    "\t\t\t  'classifier__max_depth': [3, 4, 5, 6, 7],           # The maximum depth of the tree\n",
    "\t\t\t  'classifier__max_features': [3, 4, 5],               # The number of features to consider when looking for the best split\n",
    "\t\t\t  'classifier__min_samples_leaf': [1, 2, 3, 4]                # The minimum number of samples required to be at a leaf node\n",
    "\t\t\t  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3djnpgao6WD0"
   },
   "outputs": [],
   "source": [
    "3*5*3*4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mdtg8rcU_nEa"
   },
   "source": [
    "Here, we have passed a list of parameters that the GridsearchCV algorithm will use to come at an optimum solution. It will go through every combination of this parameters to get an optimal solution. So, total iterations here will be 3 $\\times$ 5 $\\times$ 3 $\\times$ 4 = 180.\n",
    "\n",
    "`max_depth`, `max_features` and `min_samples_leaf` are the parameter for `DecisionTreeClassifier()`.\n",
    "\n",
    "To know more about `DecisionTreeClassifier()`, refer [here](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jswi6u5y7jBh"
   },
   "outputs": [],
   "source": [
    "# Instantiate GridSearchCV\n",
    "grid = GridSearchCV(estimator = pipe,                    # a scikit-learn model or pipeline\n",
    "                    param_grid = parameters,             # Dictionary with parameters names as keys and lists of parameter settings to try as values\n",
    "                    cv=2                             # Determines the cross-validation splitting strategy; to specify the number of folds in a (Stratified)KFold\n",
    "                    )\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Performance on train and test sets\n",
    "print('Training set score: ' + str(grid.score(X_train, y_train)))\n",
    "print('Test set score: ' + str(grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JCnKM224AIMm"
   },
   "source": [
    "To know more about GridSearchCV, refer [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-zNZEXAFo3a2"
   },
   "source": [
    "### Analyzing the Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vhXD4Uyh8D9L"
   },
   "outputs": [],
   "source": [
    "# Access the best set of parameters\n",
    "best_params = grid.best_params_\n",
    "print(\"Best set of parameters:\")\n",
    "print(best_params)\n",
    "\n",
    "# Stores the optimum model in best_pipe\n",
    "best_pipe = grid.best_estimator_\n",
    "print(\"\\nOptimum pipeline:\")\n",
    "print(best_pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VbarYPUJif0z"
   },
   "source": [
    "Another useful technique for analyzing the results is to construct a DataFrame from the `grid.cv_results_` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IJiM_ZhEo9pt"
   },
   "outputs": [],
   "source": [
    "# Create a dataframe\n",
    "result_df = pd.DataFrame.from_dict(grid.cv_results_, orient='columns')\n",
    "print(result_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oYYRy9QQc3vK"
   },
   "outputs": [],
   "source": [
    "result_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZiJHUyPTczoj"
   },
   "outputs": [],
   "source": [
    "result_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cGRrwxgACPJW"
   },
   "source": [
    "This DataFrame is very valuable as it shows us the scores for different parameters. The column with the `mean_test_score` is the average of the scores on the test set for all the folds during cross-validation. The DataFrame may be too big to visualize manually, hence, it is always a good idea to plot the results.\n",
    "\n",
    "Let's see how `max_depth` affect the performance for different values of `max_features`, and variance `threshold`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QuzVHZgbNlfz"
   },
   "outputs": [],
   "source": [
    "sns.relplot(data = result_df,\n",
    "            kind = 'line',\n",
    "\t\t\tx = 'param_classifier__max_depth',\n",
    "\t\t\ty = 'mean_test_score',\n",
    "\t\t\thue = 'param_classifier__max_features',\n",
    "            col = 'param_selector__threshold',\n",
    "\t\t\tpalette = ['Red', 'Green', 'Blue'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4UFZTncnDBDb"
   },
   "source": [
    "From the above plots, it can be seen that:\n",
    "\n",
    "- For all `threshold = 0.0, 0.001, 0.01`, worst performing max_features value is `3`\n",
    "- Since the `mean_test_score` is still increasing we could check for few more sets of parameter values.\n",
    "\n",
    "Let's see how `max_depth` affect the performance for different values of `min_samples_leaf`, and variance `threshold`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VB9NpUkRqi58"
   },
   "outputs": [],
   "source": [
    "sns.relplot(data = result_df,\n",
    "            kind = 'line',\n",
    "\t\t\tx = 'param_classifier__max_depth',\n",
    "\t\t\ty = 'mean_test_score',\n",
    "\t\t\thue = 'param_classifier__min_samples_leaf',\n",
    "\t\t\tcol = 'param_selector__threshold',\n",
    "            palette = ['Red', 'Green', 'Blue', 'Yellow'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VHfHdGCP_n6Y"
   },
   "source": [
    "### Please answer the questions below to complete the experiment:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VgSwVENIPcM6"
   },
   "outputs": [],
   "source": [
    "#@title Select the False statement regarding Scikit-learn Pipeline: { run: \"auto\", form-width: \"500px\", display-mode: \"form\" }\n",
    "Answer = \"With pipeline, all the preprocessing steps needs to be done separately for both training and testing set\" #@param [\"\", \"With pipeline, all the preprocessing steps needs to be done separately for both training and testing set\", \"Without pipeline, the parameters used for preprocessing of training set needs to be stored for preprocessing testing set\", \"With pipeline, doing the same preprocessing steps twice can be avoided\"]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
